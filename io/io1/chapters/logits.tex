\section{"Plain-vanilla" Logit}

\subsection{Overview}

Recall that in the pure logit model, each product has a mean quality level $\delta_j$ that incorporates the characteristics of the product as well as its price, and an idiosyncratic error term $\varepsilon_{ij}$ that is drawn iid, from a Type-I Extreme Value (or Gumbel) distribution. The Gumbel distribution has a pdf of $f(x) = e^{-x}e^{-e^{-x}}$ and a cdf of $F(x) = e^{-e^{-x}}$. We assume the variance of that distribution to be equal to $\pi^2/6$ which will normalize the scale of utility as we'll see later. The mean of the distribution is non-zero but we'll see shortly why it is not an issue. Formally, the utility derived from consumption of a good $j$ by consumer $i$ is written as: $$ U_{ij} = \delta_j + \varepsilon_{ij} $$ where $\delta_j = X_j\beta - \alpha p_j + \xi_j$. We say that a consumer chooses a good $j$ over $k$ if and only if his utility from good $j$ is strictly higher than from good $k$.

Therefore, the probability that consumer $i$ buys good $j$ is the probability that he chooses $j$ over any $k$: \begin{align*} P_{ij} = \prob{U_{ij}>U_{ik}\text{ for all } j\neq k} & = \prob{\delta_j + \varepsilon_{ij} >\delta_k + \varepsilon_{ik}\text{ for all } j\neq k} \\
& = \prob{ \varepsilon_{ij} - \varepsilon_{ik} >\delta_k - \delta_j \text{ for all } j\neq k }
\end{align*} 

It turns out that if $\varepsilon_{ij}$ and $\varepsilon_{ik}$ follow a type-I extreme value distribution independently, then the difference between both follows a logistic distribution with cdf $F(x) = \frac{e^{x}}{1+e^{x}}$. This form of the probability also tells us that constant terms in the utility across products do not matter since we consider only $\delta_j - \delta_k$ which exactly cancels any constant that we could observe. Knowing this fact, we have to ``select'' a single model by normalizing utility by substracting a same constant to all values, in particular, we can set the utility of an outside good to 0, so that $\delta_0 = 0$.

Since all error terms are independent of each other, we can write the following:\begin{align*} P_{ij}\vert \varepsilon_{ij} & = \prob{ \varepsilon_{ik} < \varepsilon_{ij} + \delta_j - \delta_k \text{ for all } j\neq k } \\ & = \prod_{k\neq j} F(\varepsilon_{ij} + \delta_j - \delta_k)
\end{align*} and since $\varepsilon_{ij}$ is not known, we compute the unconditional probability by integrating over all possible values of $\varepsilon_{ij}$ from the Gumbel distribution: $$ P_{ij} = \int \left(\prod_{k\neq j} F(\varepsilon_{ij} + \delta_j - \delta_k)\right) f(\varepsilon_{ij})\D\varepsilon_{ij} = \frac{ e^{\delta_{j}} }{ \sum_{k=0}^{J} e^{\delta_{k}} } $$

You can see that the probability of consumer $i$ buying good $j$ does not depend on any individual-only parameter or variable, so that we can express this probability of buying a good as the market share of that good $s_j$. Moreover, since we assume that utility for the outside good was 0, we have that $e^{\delta_0} = 1$. This yields the following market shares: $$s_j(\theta) = \frac{\exp(\delta_j)}{1 + \sum_{k} \exp(\delta_{k})} $$ $$s_0(\theta) = \frac{1}{1 + \sum_{k} \exp(\delta_{k})} $$

This model is very practical in the sense it is very easy to set up and displays several desirable properties:\begin{itemize}
\item $s_j = P_{ij}\in(0,1)$ so that any market share can be rationalized by the model.
\item As $\delta_{j}$ increases, reflecting higher attributed quality, the market share will increase to 1. If $\delta_j$ decreases, then the market share goes to 0. However, note that these results only hold at the limit, meaning a good will never have a market share equal to 0 or 1. If that is the case in the data, the researcher should take the product out of the dataset. This is why estimating a logit model must be done on a time-period long enough so that all goods considered have been sold at least once (think about vending machines).
\item $\sum_j s_j = 1$, meaning that one alternative will be chosen, always.
\item $s_j = P_{ij}$ is everywhere continuously differentiable in the characteristics $\delta_{j}$ and in price $p_j$.
\end{itemize}

The last point is useful to compute price derivatives (and elasticities): \begin{align*}
\frac{\partial s_j(\theta)}{\partial p_j} = \frac{-\alpha e^\delta_j \cdot (1 + \sum_{k}e^\delta_k ) + \alpha e^\delta_j e^\delta_j }{(1 + \sum_{k} e^\delta_k )^2} & = \frac{-\alpha e^\delta_j\cdot\left[ 1 + \sum_{k}e^\delta_j - e^\delta_j\right]}{(1 + \sum_{k}e^\delta_j)^2} \\ 
& = - \alpha \cdot \frac{e^\delta_j}{1 + \sum_{k}e^\delta_j} \cdot \frac{1 + \sum_{k}e^\delta_k - e^\delta_j}{1 + \sum_{k}e^\delta_k} \\
& = - \alpha s_j (1 - s_j)
\end{align*} And using the same method, we find $\partial s_j(\theta)/\partial p_k = \alpha s_j s_k $

\subsection{Logit and taste variation}\label{sssec:tastevar}

The logit model is very efficient and easy to set up if you need to measure systematic taste variation, that is, variation in tastes associated with observable characteristics $X_j$. Variations associated with idiosyncratic randomness, $\varepsilon_{ij}$ are assumed away as type-I extreme value random variables.

In reality, the value that agents put on a particular attribute varies across these individuals. Sometimes these tastes vary in an identifiable way, for example, low-income agents might more concerned about the price than others; sometimes you might observe people with the exact same observable characteristics choosing different options. Logit models allow for identification of these taste variations only within limits: if this variation is linked with observable characteristics, then logit models can be applied; if this variation is purely random, then we will require other models.

As an example, consider the choice of households between cars, where two characteristics enter the decision: price $p_j$ and shoulder room $x_j$. A household $i$ places value $U_{ij}$ on buying good $j$ such that: $$U_{ij} = \beta_i x_j - \alpha_i p_j + \varepsilon_{ij} $$ where you can see that the parameters $\alpha, \beta$ vary across households $i$. Say the shoulder room taste $\beta_i$ depends only on the number of members in the household $m_i$ such that $\beta_i = \rho M_i$; this means that $m_i$ is positively correlated with $\beta_i$. Similarly let's say the importance of price is negatively correlated to income $I$ so that $\alpha_i = \theta/I_i$. Substituting back into the utility function we get: $$U_{ij} = \rho M_i x_j - \theta p_j/I_i + \varepsilon_{ij} $$ which can be estimated with a standard logit model where variables are interaction between characteristics of the product and characteristics of the household.

In contrast, suppose taste variation was subject to an error term such that $\beta_i = \rho M_i + \mu_i$ where $\mu_i$ is non-observable (a random variable). Then the utility would be written as: $$U_{ij} = \rho M_i x_j - \theta p_j/I_i + \varepsilon_{ij} + \mu_ix_j $$ and the logit would confound the error term with $\tilde\varepsilon_{ij} = \varepsilon_{ij} + \mu_ix_j$ which is clearly correlated across product specifications and households.

Bottomline is logit models can handle systematic taste variation but not random taste variation. For the latter, we will need more complex models, such as the BLP model studied in the next chapter.

\subsection{Too-many-parameters problem}

The estimation of the quality characteristic $\delta_j$ is done over the set of non-price characteristics $X_j$. In particular, recall that we've seen that:
$$ \delta_j = X_j\beta - \alpha p_j + \xi_j $$ 

In order to identify correctly this quality term, we need that the number of different observed characteristics (the dimension of $X_j$, say $k$) is smaller than the number of products $j$. This also means that we will need to include the term $\xi_j$ in our regression in order to explain any pattern of market shares that would be unobserved by the econometrician.

However, if consumers know $\xi_j$, firms must also know it and price their products accordingly. This introduces endogeneity in the error term with respect to prices. Thus, the econometrician needs instruments to correct for that endogeneity. Typically, these instruments include cost shifters that would not affect intrinsic demand for the good but would definitely have an effect on prices.

Note that any non-price characteristic included in $X_j$ that would also be correlated with the unobservable characteristics $\xi_j$ needs to be instrumented as well.

\subsection{Derivatives and Elasticities}

The logit model presented above displays features that are not desired in the context of elasticities. These problems imply that one would run into issues while trying to expand logit results in terms of welfare analysis, antitrust analysis, etc.

First, recall the own- and cross-price derivatives and elasticities:
$$ \frac{\partial s_j}{\partial p_j}  = -\alpha s_j (1 - s_j) ; \quad \frac{\partial s_j}{\partial p_k}  = \alpha s_j s_k ; \quad \epsilon_{jj}  = -\alpha p_j (1 - s_j) ; \quad \epsilon_{jk}  = \alpha p_k s_k $$

These imply that:
\begin{itemize}

\item Two products with the same market shares will have the same markups. Indeed, from the first-order conditions, we have that: $$p_j - mc_j = \frac{1}{\vert\epsilon_{jj}\vert} \Leftrightarrow \frac{p_j - mc_j}{p_j} = \frac{1}{\alpha(1 - s_j)} $$ which would be the same for $s_j = s_k$. This is obviously not intuitive but also not observed in reality. 

\item Own-price elasticities are higher for higher priced goods. This fact comes directly from the formula of the own-price elasticity that shows a positive effect (in absolute value) from the prices. This is counter-intuitive since it would imply that people buying higher-priced items would be more price-sensitive than people buying lower-priced goods.

\item Substitution between goods only depends on relative shares and not proximity of product characteristics. In fact, cross-price elasticities are given by $\frac{\partial s_j}{\partial p_k}\frac{p_k}{s_j} = \alpha p_k s_k $, which is not a function of characteristics of neither products.

\end{itemize}

\subsection{Independence of Irrelevant Alternatives (IIA)}\label{sssec:logitiia}

We have seen in the overview of the logit model that idiosyncratic errors are independently distributed across products, following a type-I extreme value distribution. The choice of the distribution turns out not to be very important, but the independence property has some implications that the researcher should know about. In fact, the independence assumption means that the unobserved utility derived from one good ($\varepsilon_{ij}$) is unrelated unconditionally to the unobserved utility from another good. This assumption seems to be rather restrictive in the context of goods but helped us a lot in coming up with the solution of the logit model.

The independence of the error terms turns out to have problematic implications in the realism of the choice mechanism. In fact, suppose a consumer has a choice of going to work by car ($c$) or taking a blue bus ($bb$). Say that utility derived from both models are the same, such that $P_c = P_{bb} = 1/2$, meaning the ratio of probabilities is one. Now suppose that a red bus ($rb$) is introduced in the market such that it is identical in every aspect except the color to the blue bus. The probability of taking the red bus should therefore be the same as taking the blue bus: $P_{rb}/P_{bb} = 1$. However, the ratio of probabilities between the car and the blue bus has not changed because of independence of irrelevant alternatives, meaning that $P_{bb}/P_{c} = 1$, thus $P_c = P_{bb} = P_{rb} = 1/3$ is the prediction of the logit model. In real life though, we would expect the probability to take the car to remain exactly the same since the actual problem is to either take the bus (regardless of the color) or the car, yielding $P_c = 1/2, P_{bb}=P_{rb} = 1/4 $.

This IIA problem is nonetheless also a feature of the logit model when it corresponds to reality. In fact, this property allow the researcher to consider only subsets of the complete set of alternatives and still get consistent estimates, as long as for each observation, the actual choice is kept in the set. Another practical use of that property is that if the researcher is only interested in a few choices, then they do not need to include the other choices in the dataset, leaving the data research part out of the picture.

\subsection{Consumer Surplus}

For policy analysis, the researcher is often interested in measuring the change in consumer surplus that is associated with a particular event (introduction of a product, merger, etc.). Under the logit assumption, this value of the consumer surplus also takes a simple closed form that can be easily computed from the model. We know that each consumer will choose the product that yields the highest utility. In the aggregate case, all consumers have the same tastes so that in expectation (the econometrician does not observe $\varepsilon_{ij}$), consumer surplus is defined as the value of utility derived from the best good. Formally, $$\E{\operatorname{CS}} = \E{\max_{j} \{U_{ij}\}} = \E{\max_{j} \{\delta_{j} + \varepsilon_{ij} \}}$$ which yields: $$\E{\operatorname{CS}} = \ln\left(\sum_{j=1}^{J} e^{\delta_j} \right) + C $$ where $C$ is an unknown that represents the fact that absolute utility cannot be measured. This value is called the logit inclusive value, or the log-sum term. As you can see, comparing two policies is easy in this setting, let one policy be denoted by the superscript $0$ and the other by the superscript $1$. Then, $$\Delta\E{CS} = \ln\left(\sum_{\mathcal{J}^1} e^{\delta_j^1} \right) - \ln\left(\sum_{\mathcal{J}^0} e^{\delta_j^0} \right) $$

If we had transaction-level data with individual characteristics, we could perform this analysis of consumer surplus at each unit of observation and aggregate to find our results.

\section{Nested Logit}

A natural extension of the simple logit model, allowing for richer substitution patterns and a somewhat less restrictive IIA property is the nested logit model.

A nested logit model partitions the choice set in different subsets called nests such that the actual choice of one good follows from choices among nests. For example, in the simplest nested logit, with one nest, consumers first choose a nest (a category of products) as modelled in a simple logit, then within a nest, they choose a product inside the nest (again modelled as a simple logit). This sequence of logit models creates a different type of model called the nested logit. These nests are chosen by the researcher (which is not ideal) and they provide a strong structure to the model which could affect results significantly. Following the notation of Cardell (1991) and Berry (1994), we model utility as: $$U_{ij} = \delta_j + \zeta_{ig} + (1 - \sigma)\varepsilon_{ij} $$ where the new terms are: $\zeta_{ig}$ an idiosyncratic ``nest'' taste shock that applies to all goods $j$ in the nest $g$ ; and $\sigma$ a parameter of correlation in tastes within nests (if $\sigma$ is high, tastes within group are very correlated and the nest structure matters, if $\sigma$ is low, then the correlation in tastes within the nest is small and the nest structure is irrelevant). At first, it might seem that the $\sigma$ term will not allow for the simple logit model, but in fact, the $\zeta_{ig}$ error term follows a unique distribution distribution function such that $\zeta_{ig} + (1 - \sigma)\varepsilon_{ij}$ follows an extreme-value distribution (not type-I however, we call it Generalized Extreme Value or GEV). This makes $\sigma$ important to both terms, and in particular, when $\sigma \to 0$ we go to the simple logit, and $\sigma\to 1$ yields to more within-group correlation.

We know that within the same nest, the utility level  $u_{ij} = \delta_j + \zeta_{ig} (1 - \sigma) + \varepsilon_{ij}$, can be reduced down to ignore the effect of $\zeta$, since it is the same across products. We end up in the same setting as the simple logit model. This implies that the conditional share of product $j$, or the share within the nest, is given by the same formula as the simple logit: $$s_{j\vert g} = \frac{\exp(\delta_j/(1-\sigma))}{\sum_{k\in\mathcal{J}_g} \exp(\delta_k/(1-\sigma))} $$ where the denominator for this expression can be written as $D_g$, the total demand for products in the group $g$.

Meanwhile, across groups, we have that both error terms still give a type-I EV, so again, we can think about the demand for a group as we did in the logit case: $$s_g = \frac{D_g^{(1-\sigma)}}{\sum_{h} D_h^{(1-\sigma)}} $$ Finally, the share of a product $j$ is given by the product of both the share of the group containing $j$ and the conditional share of $j$ within the group: $$s_j = s_{j\vert g} \cdot s_g = \frac{\exp(\delta_j/(1-\sigma))}{D_g^\sigma\cdot\left(\sum_{h} D_h^{(1-\sigma)}\right)} $$ As we can see, demand for product $j$ depends on its own quality level relative to its group, the quality of the group relative to the other groups and $\sigma$, the correlation in tastes within nests.

The outside good in this model is considered as one of its own group, so that $s_{0\vert 0} = 1$ and with the normalization of $\delta_0 = 0$ and $D_0 = 1$, we get:$$s_{0} = 1\cdot s_0 = \frac{1}{\sum_h D_h^{(1-\sigma)}} $$

This analytical derivation is the same when we extend the model to have nests within nests and more.

\subsection{IIA and substitution patterns}

The nest structure of this model satisfies two properties:\begin{enumerate}

\item For any two alternatives that are in the same nest, the ratio of probabilities is independent of the attributes and/or existence of other products in the nest or in other nests. $$ s_j / s_k = s_{j\vert g} / s_{k\vert g} = \frac{\exp(\delta_j/(1-\sigma))}{\exp(\delta_k/(1-\sigma))} $$ Equivalently, we say that IIA holds within the nest.

\item For any two alternatives that are in different nests, the ratio of probabilities depends on the attributes and/or existence of other products in the two nests. $$ s_j / s_k = s_{j\vert g} / s_{k\vert h} \cdot s_g / s_h  = \frac{\exp(\delta_j/(1-\sigma))}{\exp(\delta_k/(1-\sigma))} \cdot \frac{D_g^{1-\sigma}}{D_h^{1-\sigma}} $$ Equivalently, we say that IIA does not hold across nests.
\end{enumerate}

\subsection{Research considerations}

As we have seen, the nested logit is a fairly simple extension on the simple logit case, which relies on relaxation of the IIA property across groups (or nests). The model is often told in a narrative of sequential choice: consumers first choose a group $g$ ($s_g$), then a product (or group) $j$ within group $g$ ($s_{j\vert g}$). 

The results of the model depend very strongly on the ex ante nesting structure chosen by the researcher. Therefore, it is very important (and hard) to understand what the appropriate structure should be. The sequential narrative is supposed to help the researcher come up with an accurate structure but it might be unhelpful at times.

Identification comes in different flavors:\begin{itemize}
\item Parameters associated with characteristics and prices are identified within group by variation in these exact characteristics.
\item The correlation in tastes parameter ($\sigma$) is identified by variation in 
\end{itemize}

\section{Multinomial Probit}

The multinomial probit is a more flexible alternative to the simple logit model. In fact, by allowing errors $\varepsilon_{ij}$ to be correlated (not iid) and to follow a multivariate normal distribution $N(\mu, \Sigma)$ that is completely free, it achieves more interesting outcomes than the simple logit. For example, with an unrestricted variance matrix $\Sigma$, you could end up with substitution patterns that are more...

\section{GMM Estimation Strategy for Product-level data}

The general estimation strategy that applies to logit models with product-level data is detailed in the following steps:\begin{enumerate}
\item Assume that data is drawn from markets with large $n$.
\item Assume that observed market shares are measured without errors.
\item For each $\theta$ (vector of parameters), there exists a unique $\xi$ such that the model shares and observed shares are equal ($J$ equations, $J$ unknowns).
\item We invert the model to get $\xi$ as a function of the parameters. How this step is performed depends on the functional form of the model.
\item Using $\xi$, we can create the moments of the model, estimating them by GMM. 
\end{enumerate}

\subsection{Inversion in the logit case}

We need to express the quality unobservable term $\xi_j$ in terms of all observable characteristics. First, recall that: $$ \delta_j = X_j\beta - \alpha p_j + \xi_j $$ but in this equation, $\delta_j$ is unknown (there is no such thing as a perceived mean quality level). Nevertheless, we can use the market shares formulas that link the $\delta_j$ to the observed market shares $s_j$ (observed without errors). Thus, $$s_j = \frac{\exp(\delta_j)}{1 + \sum_k \exp(\delta_k) } $$ but again, we run into a problem since it is expressed as a function of other $\delta_k$: we could solve a system of equations, or simplify the model using the normalized good. Indeed, $$\frac{s_j}{s_0} = \exp(\delta_j) \Leftrightarrow \ln(s_j) - \ln(s_0) = \delta_j \Leftrightarrow \ln(s_j) - \ln(s_0) = X_j\beta - \alpha p_j + \xi_j $$ which in turn yields the inversion equation: $$
\ln(s_j) - \ln(s_0) +  \alpha p_j  - X_j\beta = \xi_j $$

\subsection{Inversion in the nested-logit case}

In the same way as in the simple logit model, our main objective is to get the link between $\delta_j$ and observables so that we can identify $\xi_j$. In this case: $$s_j = \frac{\exp(\delta_j/(1-\sigma))}{D_g^\sigma\cdot\left(\sum_{h} D_h^{(1-\sigma)}\right)} \text{ and } s_0 = \frac{1}{\sum_{h} D_h^{(1-\sigma)}} $$ so that $$\ln(s_j) - \ln(s_0) = \frac{1}{1-\sigma}\cdot \delta_j - \sigma\ln(D_g) $$ We turn into a new problem caused by the two-level structure, which is $D_g$ is not parameterized. Again, we solve this issue by using the normalized good: $$ s_g / s_0 = D_g^{(1-\sigma)} \Leftrightarrow \ln(s_g) - \ln(s_0) = (1-\sigma) \cdot \ln(D_g) $$ which we can plug back in the previous equation to get: $$\ln(s_j) - \ln(s_0) = \frac{1}{1-\sigma}\cdot \delta_j - \frac{\sigma}{1 - \sigma} [ \ln(s_g) - \ln(s_0) ] $$ $$\Leftrightarrow (1 - \sigma) \cdot [\ln(s_j) - \ln(s_0)] = \delta_j - \sigma [ \ln(s_g) - \ln(s_0) ] $$ $$\Leftrightarrow (1 - \sigma) \cdot \ln(s_j) + \sigma \ln(s_g) - \ln(s_0) = \delta_j $$ Finally, using the fact that $s_g = s_j / s_{j\vert g} \Leftrightarrow \ln(s_g) = \ln(s_j) - \ln(s_{j\vert g})$, we can get: $$\Leftrightarrow \ln(s_j) - \sigma \ln(s_{j\vert g}) - \ln(s_0) - X_j\beta + \alpha p_j = \xi_j $$

\subsection{Endogeneity issues}

Regardless of the model we use, we will have to deal with endogeneity issues regarding many dimensions, such as prices, observable characteristics or market shares. 

In fact, in both models price was correlated to the unobservable term as firms make their decision based on demand which includes this term; moreover, in the nested logit case, we also have to deal with endogeneity in the within-share term. In general, anything that is correlated with the unobservable quality term $\xi$ will have to be instrumented.



In the particular case of the nested logit model, you should realize that conditional market shares and actual market shares depend on the same "function", which means we also need to instrument for one of these shares. ...

\subsection{Measurement errors}

Measurement errors in observed prices, characteristics or quantities may also create difficulties for the estimation procedure outlined above. Prices enter linearly in the estimation and are already endogenous so that these errors do not create too important biases. However, when these errors are present in market shares or quantities data then this issue becomes more important. Indeed, market share data is used to invert the model and get the unobservable term as a function of observed data. This non-linear inversion will in fact be very sensitive to measurement errors in the market shares.

\subsection{Adding supply-side restrictions}



\section{Individual-level data}


